{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec590164",
   "metadata": {},
   "source": [
    "# Assessment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ad4629",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c613d91b",
   "metadata": {},
   "source": [
    "This is the assessment for the Statistics in Practice - Python Module. It counts as 30% of your overall mark for the module.\n",
    "\n",
    "The assessment is to be undertaken individually. Your work must be submitted in the form of a single jupyter notebook. \n",
    "The assessments will be released during the workshops, and are due a week later. Please check the submission box for the exact submission deadline. \n",
    "Before your results and feedback are returned you might be asked to have a short (approximately 5 minutes) individual \"interview\" to discuss some aspects of your work. The outcome of this interview might impact on your overall individual score.\n",
    "\n",
    "The three assessments are equally weighted.\n",
    "\n",
    "To score full marks in the questions you must show all of your code and calculations, make good use of plots for visualising and summarising your data, discuss any limitations associated with your approach, and comment your code.\n",
    "The questions are \"exploratory\" in nature, so you are expected to reflect on what you are being asked to do and research the methods being developed. For example, you might choose to investigate what the effect of the quadrat size has on the power of the method for determining non randomness, or you might want to say something about how the likelihood of a obtaining a particular result might be quantified, and so on ....\n",
    "\n",
    "\n",
    "You can use the internet to search for examples of python code that may be useful, but do make reference to your sources. \n",
    "\n",
    "If you have any questions regarding the course and / or the assessment, please do not hesitate to contact me by [e-mail](mailto:e.campillo-funollet@lancaster.ac.uk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b2b254",
   "metadata": {},
   "source": [
    "## Part 2.1\n",
    "\n",
    "Using __numpy__ or otherwise, generate some exampes of non-uniformly distributed points in the plane and see if the mean nearest neighbour distances are contained inside an appropriately determined 95% confidence interval.\n",
    "\n",
    "How good do you think the statistic proposed by Clark and Evans is for determining if spatial points are randomly distributed ?\n",
    "\n",
    "It is possible to create a non-random(pathological) data set that has a mean nearest neighbour distance equal to the Clarkand Evans statistic. Can you create/describe such a set of data ? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bf0f80",
   "metadata": {},
   "source": [
    "## Part 2.2\n",
    "\n",
    "The statistic proposed by Clark and Evans can be useful for determining non-randomness in spatial data, but it does not quantify how the data deviates from the assumption of randomness. The use of quadrat based methods can help describe how a spatial pattern is distributed.\n",
    "\n",
    "Typically, a quadrat based method uses a contiguous regular grid to \"bin\" the spatially distributed data into counts. If the bins are of equal size, and the data is randomly distributed in the region of the grid, then the counts $x$ in each bin would be expected to have a poisson distribution\n",
    "\n",
    "$P(x) = \\frac{{\\rm e}^{\\lambda}\\lambda^{x}}{x!}$\n",
    "\n",
    "\n",
    "For $N$ samples and a grid with area $S$ and quadrat area $A$ the value of $\\lambda$ is \n",
    "\n",
    "$\\lambda = N\\frac{A}{S}$\n",
    "\n",
    "\n",
    "Use Python to automate the process of generating the coordinates of the vertices of a $n$ by $m$ grid made up of rectangles of dimensions $\\delta x$,$\\delta y$.  Your data should be in a pandas data frame and each row should have two x coordinates and two y coordinates which define each quadrat in the grid. Your data frame might look something like the one shown below\n",
    "\n",
    "\n",
    "\n",
    "| | x0 | x1 | y0 | y1 |\n",
    "|- | - | - | - | - |\n",
    "|0 |0.0 |\t0.1 |\t0.0 |\t0.1|\n",
    "|1 \t|0.0 |\t0.1 |\t0.1 |\t0.2|\n",
    "|2 \t|0.0 |\t0.1 |\t0.2 |\t0.3|\n",
    "|3 \t|0.0 |\t0.1 |\t0.3 |\t0.4|\n",
    "|4 \t|0.0 |\t0.1 |\t0.4 |\t0.5|\n",
    "|... | \t... |\t... |\t...| \t...|\n",
    "|95 |\t0.9 |\t1.0 |\t0.5 |\t0.6|\n",
    "|96 |\t0.9 |\t1.0 |\t0.6 |\t0.7|\n",
    "|97 |\t0.9 |\t1.0 |\t0.7 |\t0.8|\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
